#!/usr/bin/env python3
# /// script
# requires-python = ">=3.10"
# dependencies = []
# ///

"""
Ticket Quality Gate Hook

è‡ªå‹•æª¢æ¸¬ Ticket å“è³ªï¼ˆC1/C2/C3 Code Smellï¼‰

ä½¿ç”¨æ–¹å¼:
    PostToolUse Hook è‡ªå‹•è§¸ç™¼ï¼Œæˆ–æ‰‹å‹•æ¸¬è©¦:
    echo '{"tool_name":"Write","tool_input":{"file_path":"test.md","content":"..."}}' | python3 ticket-quality-gate-hook.py

ç’°å¢ƒè®Šæ•¸:
    HOOK_DEBUG: å•Ÿç”¨è©³ç´°æ—¥èªŒï¼ˆtrue/falseï¼‰
"""

import sys
import json
import logging
import hashlib
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, Optional

# å°å…¥æ¨¡çµ„ï¼ˆç›¸å°å°å…¥ï¼‰
sys.path.insert(0, str(Path(__file__).parent))
from ticket_quality.detectors import (
    check_god_ticket_automated,
    check_incomplete_ticket_automated,
    check_ambiguous_responsibility_automated
)
from ticket_quality.reporters import (
    generate_markdown_report,
    generate_json_report
)

# å…¨åŸŸå¸¸æ•¸
EXIT_SUCCESS = 0
EXIT_ERROR = 1
EXIT_BLOCK = 2

# å…¨åŸŸå¿«å–ï¼ˆè¨˜æ†¶é«”ï¼‰
_check_cache: Dict[str, Dict[str, Any]] = {}
_cache_ttl = timedelta(minutes=5)  # 5 åˆ†é˜å¿«å–

# å¿«å–çµ±è¨ˆé è¨­å€¼
DEFAULT_CACHE_STATS = {
    "total_checks": 0,
    "cache_hits": 0,
    "cache_misses": 0,
    "avg_execution_time_with_cache": 0.0,
    "avg_execution_time_without_cache": 0.0,
    "last_updated": "",
    "version": "v0.12.G.4"
}


def setup_logging() -> None:
    """åˆå§‹åŒ–æ—¥èªŒç³»çµ±"""
    import os

    log_level = logging.DEBUG if os.getenv("HOOK_DEBUG") == "true" else logging.INFO

    # å»ºç«‹æ—¥èªŒç›®éŒ„
    project_dir = Path(os.getenv("CLAUDE_PROJECT_DIR", Path.cwd()))
    log_dir = project_dir / ".claude" / "hook-logs" / "ticket-quality-gate"
    log_dir.mkdir(parents=True, exist_ok=True)

    log_file = log_dir / "ticket-quality-gate.log"

    logging.basicConfig(
        level=log_level,
        format="[%(asctime)s] %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler(sys.stderr)
        ]
    )


def read_json_from_stdin() -> Dict[str, Any]:
    """
    å¾ stdin è®€å– JSON è¼¸å…¥

    Returns:
        dict - è§£æå¾Œçš„ JSON è³‡æ–™

    Raises:
        ValueError: JSON æ ¼å¼éŒ¯èª¤
    """
    try:
        input_data = json.load(sys.stdin)
        logging.debug(f"è¼¸å…¥ JSON: {json.dumps(input_data, ensure_ascii=False, indent=2)}")
        return input_data
    except json.JSONDecodeError as e:
        logging.error(f"JSON è§£æéŒ¯èª¤: {e}")
        raise ValueError(f"Invalid JSON input: {e}")


def validate_input(input_data: Dict[str, Any]) -> bool:
    """
    é©—è­‰è¼¸å…¥æ ¼å¼

    Args:
        input_data: Hook è¼¸å…¥è³‡æ–™

    Returns:
        bool - è¼¸å…¥æ ¼å¼æ˜¯å¦æ­£ç¢º
    """
    required_fields = ["tool_name", "tool_input"]

    for field in required_fields:
        if field not in input_data:
            logging.error(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {field}")
            return False

    tool_input = input_data.get("tool_input", {})
    if "file_path" not in tool_input or "content" not in tool_input:
        logging.error("tool_input ç¼ºå°‘ file_path æˆ– content")
        return False

    return True


def should_trigger_check(input_data: Dict[str, Any]) -> bool:
    """
    åˆ¤æ–·æ˜¯å¦æ‡‰è§¸ç™¼æª¢æ¸¬

    æ¢ä»¶:
    1. å·¥å…·é¡å‹ç‚º Write/Edit/MultiEdit
    2. æª”æ¡ˆå‰¯æª”åç‚º .md
    3. æª”æ¡ˆè·¯å¾‘åŒ…å« Ticket ç›¸é—œé—œéµå­—
    4. æª”æ¡ˆå…§å®¹åŒ…å« Ticket çµæ§‹æ¨™è¨˜

    Args:
        input_data: Hook è¼¸å…¥è³‡æ–™

    Returns:
        bool - æ˜¯å¦æ‡‰è§¸ç™¼æª¢æ¸¬
    """
    # æ¢ä»¶ 1: å·¥å…·é¡å‹æª¢æŸ¥
    tool_name = input_data.get("tool_name", "")
    if tool_name not in ["Write", "Edit", "MultiEdit"]:
        logging.info(f"å·¥å…·é¡å‹ä¸ç¬¦: {tool_name}")
        return False

    # æ¢ä»¶ 2: æª”æ¡ˆé¡å‹æª¢æŸ¥
    file_path = input_data["tool_input"]["file_path"]
    if not file_path.endswith(".md"):
        logging.info(f"æª”æ¡ˆé¡å‹ä¸ç¬¦: {file_path}")
        return False

    # æ¢ä»¶ 3: æª”æ¡ˆè·¯å¾‘é—œéµå­—æª¢æŸ¥
    ticket_path_keywords = [
        "docs/work-logs/",
        "docs/tickets/",
        "-ticket-",
        "-task-"
    ]
    if not any(keyword in file_path for keyword in ticket_path_keywords):
        logging.info(f"æª”æ¡ˆè·¯å¾‘ä¸ç¬¦åˆ Ticket æ ¼å¼: {file_path}")
        return False

    # æ¢ä»¶ 4: æª”æ¡ˆå…§å®¹çµæ§‹æª¢æŸ¥
    content = input_data["tool_input"]["content"]
    ticket_structure_markers = [
        "## ğŸ“‹ å¯¦ä½œæ­¥é©Ÿ",
        "## âœ… é©—æ”¶æ¢ä»¶",
        "## ğŸ”— åƒè€ƒæ–‡ä»¶",
        "Layer 1", "Layer 2", "Layer 3", "Layer 4", "Layer 5"
    ]
    if not any(marker in content for marker in ticket_structure_markers):
        logging.info("æª”æ¡ˆå…§å®¹ä¸ç¬¦åˆ Ticket çµæ§‹")
        return False

    logging.info(f"è§¸ç™¼æ¢ä»¶æª¢æŸ¥é€šé: {file_path}")
    return True


def calculate_file_hash(content: str) -> str:
    """
    è¨ˆç®—æª”æ¡ˆå…§å®¹ hash

    Args:
        content: æª”æ¡ˆå…§å®¹

    Returns:
        str - MD5 hash
    """
    return hashlib.md5(content.encode()).hexdigest()


def should_skip_check_due_to_cache(file_path: str, file_hash: str) -> bool:
    """
    æª¢æŸ¥æ˜¯å¦æ‡‰è·³éæª¢æ¸¬ï¼ˆåŸºæ–¼å¿«å–ï¼‰

    å¿«å–å‘½ä¸­æ¢ä»¶:
    1. å¿«å–ä¸­å­˜åœ¨è©²æª”æ¡ˆ
    2. æ™‚é–“æœªéæœŸï¼ˆ< 5 åˆ†é˜ï¼‰
    3. æª”æ¡ˆ hash æœªè®Šæ›´

    Args:
        file_path: æª”æ¡ˆè·¯å¾‘
        file_hash: æª”æ¡ˆå…§å®¹ hash

    Returns:
        bool - True è¡¨ç¤ºæ‡‰è·³éï¼ˆå¿«å–å‘½ä¸­ï¼‰ï¼ŒFalse è¡¨ç¤ºæ‡‰åŸ·è¡Œæª¢æ¸¬
    """
    # æª¢æŸ¥å¿«å–æ˜¯å¦å­˜åœ¨
    if file_path not in _check_cache:
        logging.debug(f"å¿«å–æœªå‘½ä¸­: {file_path}")
        return False

    cached_entry = _check_cache[file_path]
    cached_time = cached_entry["time"]
    cached_hash = cached_entry["hash"]

    # æª¢æŸ¥ 1: æ™‚é–“æ˜¯å¦éæœŸ
    if datetime.now() - cached_time > _cache_ttl:
        logging.debug(f"å¿«å–éæœŸ: {file_path}")
        del _check_cache[file_path]
        return False

    # æª¢æŸ¥ 2: æª”æ¡ˆå…§å®¹æ˜¯å¦è®Šæ›´
    if cached_hash != file_hash:
        logging.debug(f"æª”æ¡ˆå…§å®¹å·²è®Šæ›´: {file_path}")
        del _check_cache[file_path]
        return False

    # å¿«å–å‘½ä¸­
    logging.info(f"å¿«å–å‘½ä¸­: {file_path}")
    return True


def update_check_cache(file_path: str, file_hash: str, check_results: Dict[str, Any]) -> None:
    """
    æ›´æ–°å¿«å–

    Args:
        file_path: æª”æ¡ˆè·¯å¾‘
        file_hash: æª”æ¡ˆå…§å®¹ hash
        check_results: æª¢æ¸¬çµæœ
    """
    _check_cache[file_path] = {
        "hash": file_hash,
        "time": datetime.now(),
        "result": check_results
    }
    logging.debug(f"å¿«å–å·²æ›´æ–°: {file_path}")


def cleanup_expired_cache() -> None:
    """æ¸…ç†éæœŸå¿«å–ï¼ˆé¿å…è¨˜æ†¶é«”æ´©æ¼ï¼‰"""
    current_time = datetime.now()
    expired_keys = [
        file_path for file_path, cached_entry in _check_cache.items()
        if current_time - cached_entry["time"] > _cache_ttl
    ]

    for key in expired_keys:
        del _check_cache[key]
        logging.debug(f"æ¸…ç†éæœŸå¿«å–: {key}")

    if expired_keys:
        logging.info(f"æ¸…ç†äº† {len(expired_keys)} å€‹éæœŸå¿«å–æ¢ç›®")


def get_cache_stats_dir() -> Path:
    """
    å–å¾—å¿«å–çµ±è¨ˆç›®éŒ„è·¯å¾‘

    Returns:
        Path - å¿«å–çµ±è¨ˆç›®éŒ„
    """
    import os
    project_dir = Path(os.getenv("CLAUDE_PROJECT_DIR", Path.cwd()))
    cache_dir = project_dir / ".claude" / "hook-logs" / "ticket-quality-gate" / "cache"
    cache_dir.mkdir(parents=True, exist_ok=True)
    return cache_dir


def load_cache_stats() -> Dict[str, Any]:
    """
    è¼‰å…¥å¿«å–çµ±è¨ˆè³‡æ–™

    Returns:
        dict - å¿«å–çµ±è¨ˆè³‡æ–™
    """
    cache_dir = get_cache_stats_dir()
    stats_file = cache_dir / "cache_stats.json"

    if not stats_file.exists():
        return DEFAULT_CACHE_STATS.copy()

    try:
        with open(stats_file, 'r', encoding='utf-8') as f:
            stats = json.load(f)
        logging.debug("å¿«å–çµ±è¨ˆè³‡æ–™è¼‰å…¥æˆåŠŸ")
        return stats
    except Exception as e:
        logging.warning(f"å¿«å–çµ±è¨ˆè³‡æ–™è¼‰å…¥å¤±æ•—ï¼Œä½¿ç”¨é è¨­å€¼: {e}")
        return DEFAULT_CACHE_STATS.copy()


def save_cache_stats(stats: Dict[str, Any]) -> None:
    """
    å„²å­˜å¿«å–çµ±è¨ˆè³‡æ–™

    Args:
        stats: å¿«å–çµ±è¨ˆè³‡æ–™
    """
    cache_dir = get_cache_stats_dir()
    stats_file = cache_dir / "cache_stats.json"

    try:
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        logging.debug("å¿«å–çµ±è¨ˆè³‡æ–™å„²å­˜æˆåŠŸ")
    except Exception as e:
        # å¿«å–çµ±è¨ˆå¤±æ•—ä¸æ‡‰è©²é˜»æ­¢ Hook åŸ·è¡Œ
        logging.warning(f"å¿«å–çµ±è¨ˆè³‡æ–™å„²å­˜å¤±æ•—: {e}")


def update_cache_stats(cache_hit: bool, execution_time: float) -> None:
    """
    æ›´æ–°å¿«å–çµ±è¨ˆè³‡æ–™

    ä½¿ç”¨æŒ‡æ•¸ç§»å‹•å¹³å‡ï¼ˆEMAï¼‰è¨ˆç®—å¹³å‡åŸ·è¡Œæ™‚é–“ï¼Œé¿å…èˆŠè³‡æ–™éåº¦å½±éŸ¿

    Args:
        cache_hit: æ˜¯å¦å‘½ä¸­å¿«å–
        execution_time: åŸ·è¡Œæ™‚é–“ï¼ˆç§’ï¼‰
    """
    try:
        stats = load_cache_stats()

        # æ›´æ–°çµ±è¨ˆè³‡æ–™
        stats["total_checks"] += 1

        # æŒ‡æ•¸ç§»å‹•å¹³å‡ï¼ˆalpha=0.1ï¼Œè¼ƒé‡è¦–æ–°è³‡æ–™ï¼‰
        alpha = 0.1

        if cache_hit:
            stats["cache_hits"] += 1
            prev_avg = stats.get("avg_execution_time_with_cache", execution_time)
            stats["avg_execution_time_with_cache"] = (
                alpha * execution_time + (1 - alpha) * prev_avg
            )
        else:
            stats["cache_misses"] += 1
            prev_avg = stats.get("avg_execution_time_without_cache", execution_time)
            stats["avg_execution_time_without_cache"] = (
                alpha * execution_time + (1 - alpha) * prev_avg
            )

        stats["last_updated"] = datetime.now().isoformat()

        # å„²å­˜çµ±è¨ˆè³‡æ–™
        save_cache_stats(stats)

        logging.info(
            f"å¿«å–çµ±è¨ˆæ›´æ–°ï¼šå‘½ä¸­={cache_hit}, åŸ·è¡Œæ™‚é–“={execution_time:.3f}s, "
            f"ç¸½æª¢æ¸¬={stats['total_checks']}, å‘½ä¸­ç‡={(stats['cache_hits'] / stats['total_checks'] * 100):.1f}%"
        )
    except Exception as e:
        logging.warning(f"æ›´æ–°å¿«å–çµ±è¨ˆå¤±æ•—: {e}")


def generate_cache_stats_report() -> str:
    """
    ç”Ÿæˆå¿«å–çµ±è¨ˆå ±å‘Šï¼ˆMarkdown æ ¼å¼ï¼‰

    Returns:
        str: Markdown æ ¼å¼çš„çµ±è¨ˆå ±å‘Š
    """
    try:
        stats = load_cache_stats()

        # è¨ˆç®—å‘½ä¸­ç‡
        total = stats.get("total_checks", 0)
        hits = stats.get("cache_hits", 0)
        hit_rate = (hits / total * 100) if total > 0 else 0

        # è¨ˆç®—æ•ˆèƒ½æå‡
        with_cache = stats.get("avg_execution_time_with_cache", 0)
        without_cache = stats.get("avg_execution_time_without_cache", 0)
        speedup = (without_cache / with_cache) if with_cache > 0 else 1.0

        report = f"""## ğŸ“Š å¿«å–çµ±è¨ˆå ±å‘Š

**ç‰ˆæœ¬**: {stats.get("version", "unknown")}
**æœ€å¾Œæ›´æ–°**: {stats.get("last_updated", "N/A")}

### ç¸½è¦½

- **ç¸½æª¢æ¸¬æ¬¡æ•¸**: {total:,}
- **å¿«å–å‘½ä¸­**: {hits:,} ({hit_rate:.1f}%)
- **å¿«å–æœªå‘½ä¸­**: {stats.get("cache_misses", 0):,} ({100 - hit_rate:.1f}%)

### åŸ·è¡Œæ™‚é–“

- **å¿«å–å‘½ä¸­å¹³å‡æ™‚é–“**: {with_cache:.3f}s
- **å¿«å–æœªå‘½ä¸­å¹³å‡æ™‚é–“**: {without_cache:.3f}s
- **æ•ˆèƒ½æå‡**: {speedup:.1f}x

### æ•ˆèƒ½è©•ç´š

"""

        # æ•ˆèƒ½è©•ç´š
        if hit_rate >= 70:
            report += "âœ… **å„ªç§€** - å¿«å–å‘½ä¸­ç‡ > 70%\n"
        elif hit_rate >= 50:
            report += "ğŸŸ¡ **è‰¯å¥½** - å¿«å–å‘½ä¸­ç‡ 50-70%\n"
        else:
            report += "ğŸ”´ **éœ€æ”¹å–„** - å¿«å–å‘½ä¸­ç‡ < 50%\n"

        report += "\n---\n\n_æ­¤çµ±è¨ˆç”± Ticket Quality Gate Hook è‡ªå‹•ç”Ÿæˆ_\n"

        return report
    except Exception as e:
        logging.warning(f"ç”Ÿæˆå¿«å–çµ±è¨ˆå ±å‘Šå¤±æ•—: {e}")
        return """## ğŸ“Š å¿«å–çµ±è¨ˆå ±å‘Š

_ç„¡çµ±è¨ˆè³‡æ–™_

å¿«å–çµ±è¨ˆå°‡åœ¨é¦–æ¬¡åŸ·è¡Œå¾Œé–‹å§‹è¨˜éŒ„ã€‚
"""


def run_check_with_error_handling(check_name: str, check_function) -> Dict[str, Any]:
    """
    åŸ·è¡Œæª¢æ¸¬å‡½å¼ï¼Œè™•ç†ç•°å¸¸

    ç­–ç•¥: æ•æ‰æ‰€æœ‰ç•°å¸¸ï¼Œå›å‚³éŒ¯èª¤ç‹€æ…‹è€Œéæ‹‹å‡º

    Args:
        check_name: æª¢æ¸¬åç¨±
        check_function: æª¢æ¸¬å‡½å¼

    Returns:
        dict - æª¢æ¸¬çµæœæˆ–éŒ¯èª¤è³‡è¨Š
    """
    try:
        logging.info(f"åŸ·è¡Œ {check_name} æª¢æ¸¬...")
        result = check_function()
        logging.info(f"{check_name} æª¢æ¸¬å®Œæˆï¼Œç‹€æ…‹: {result['status']}")
        return result

    except Exception as e:
        logging.error(f"{check_name} æª¢æ¸¬å¤±æ•—: {e}", exc_info=True)
        return {
            "status": "error",
            "confidence": 0.0,
            "error_message": str(e),
            "error_type": type(e).__name__
        }


def run_all_checks(ticket_content: str, file_path: str) -> Dict[str, Any]:
    """
    åŸ·è¡Œæ‰€æœ‰ Code Smell æª¢æ¸¬

    ç­–ç•¥: å³ä½¿éƒ¨åˆ†æª¢æ¸¬å¤±æ•—ï¼Œä»å›å‚³å…¶ä»–æª¢æ¸¬çµæœ

    Args:
        ticket_content: Ticket å…§å®¹
        file_path: æª”æ¡ˆè·¯å¾‘

    Returns:
        dict - å®Œæ•´æª¢æ¸¬çµæœ
    """
    results = {
        "file_path": file_path,
        "check_time": datetime.now().isoformat(),
        "checks": {},
        "summary": {
            "total_checks": 3,
            "passed": 0,
            "failed": 0,
            "warnings": 0,
            "errors": 0
        }
    }

    # C1 æª¢æ¸¬
    results["checks"]["c1_god_ticket"] = run_check_with_error_handling(
        "C1 God Ticket",
        lambda: check_god_ticket_automated(ticket_content)
    )
    update_summary(results, "c1_god_ticket")

    # C2 æª¢æ¸¬
    results["checks"]["c2_incomplete_ticket"] = run_check_with_error_handling(
        "C2 Incomplete Ticket",
        lambda: check_incomplete_ticket_automated(ticket_content)
    )
    update_summary(results, "c2_incomplete_ticket")

    # C3 æª¢æ¸¬
    results["checks"]["c3_ambiguous_responsibility"] = run_check_with_error_handling(
        "C3 Ambiguous Responsibility",
        lambda: check_ambiguous_responsibility_automated(ticket_content)
    )
    update_summary(results, "c3_ambiguous_responsibility")

    # è¨ˆç®—æ•´é«”ç‹€æ…‹å’Œä¿¡å¿ƒåº¦
    results["overall_status"] = calculate_overall_status(results)
    results["overall_confidence"] = calculate_overall_confidence(results)

    # æ”¶é›†éœ€äººå·¥å¯©æŸ¥é …ç›®
    results["summary"]["needs_human_review"] = collect_needs_human_review(results)

    return results


def update_summary(results: Dict[str, Any], check_key: str) -> None:
    """
    æ›´æ–°æª¢æ¸¬æ‘˜è¦

    Args:
        results: æª¢æ¸¬çµæœ
        check_key: æª¢æ¸¬éµå
    """
    check_result = results["checks"][check_key]
    status = check_result.get("status", "unknown")

    if status == "passed":
        results["summary"]["passed"] += 1
    elif status == "failed":
        results["summary"]["failed"] += 1
    elif status == "warning":
        results["summary"]["warnings"] += 1
    elif status == "error":
        results["summary"]["errors"] += 1


def calculate_overall_status(results: Dict[str, Any]) -> str:
    """
    è¨ˆç®—æ•´é«”ç‹€æ…‹

    Args:
        results: æª¢æ¸¬çµæœ

    Returns:
        str - "passed" / "failed" / "warning" / "error" / "partial"
    """
    summary = results["summary"]

    if summary["errors"] == summary["total_checks"]:
        return "error"
    elif summary["errors"] > 0:
        return "partial"
    elif summary["failed"] > 0:
        return "failed"
    elif summary["warnings"] > 0:
        return "warning"
    else:
        return "passed"


def calculate_overall_confidence(results: Dict[str, Any]) -> float:
    """
    è¨ˆç®—æ•´é«”ä¿¡å¿ƒåº¦

    Args:
        results: æª¢æ¸¬çµæœ

    Returns:
        float - æ•´é«”ä¿¡å¿ƒåº¦ (0.0-1.0)
    """
    checks = results["checks"]
    confidences = []

    for check_key, check_result in checks.items():
        if check_result.get("status") != "error":
            confidences.append(check_result.get("confidence", 0.0))

    if not confidences:
        return 0.0

    # å¦‚æœæœ‰å¤±æ•—ï¼Œä½¿ç”¨å¹³å‡å€¼ï¼›å¦‚æœå…¨éƒ¨é€šéï¼Œä½¿ç”¨æœ€å°å€¼ï¼ˆä¿å®ˆè©•ä¼°ï¼‰
    if results["overall_status"] == "failed":
        return sum(confidences) / len(confidences)
    else:
        return min(confidences)


def collect_needs_human_review(results: Dict[str, Any]) -> list:
    """
    æ”¶é›†éœ€äººå·¥å¯©æŸ¥çš„é …ç›®

    Args:
        results: æª¢æ¸¬çµæœ

    Returns:
        list - éœ€äººå·¥å¯©æŸ¥çš„æª¢æ¸¬é …ç›®åç¨±
    """
    needs_review = []

    for check_key, check_result in results["checks"].items():
        if check_result.get("needs_human_review", False):
            needs_review.append(check_key)

    return needs_review


def generate_hook_output(check_results: Dict[str, Any]) -> Dict[str, Any]:
    """
    ç”Ÿæˆ Hook è¼¸å‡ºæ ¼å¼

    Args:
        check_results: æª¢æ¸¬çµæœ

    Returns:
        dict - Hook è¼¸å‡º JSON
    """
    # ç”Ÿæˆ Markdown å ±å‘Š
    markdown_report = generate_markdown_report(
        check_results,
        check_results["file_path"]
    )

    # æ±ºå®š decision å’Œ reason
    decision, reason = determine_decision(check_results)

    return {
        "decision": decision,
        "reason": reason,
        "hookSpecificOutput": {
            "hookEventName": "PostToolUse",
            "additionalContext": markdown_report
        },
        "check_results": check_results
    }


def determine_decision(check_results: Dict[str, Any]) -> tuple:
    """
    æ ¹æ“šæª¢æ¸¬çµæœæ±ºå®š decision å’Œ reason

    è¦å‰‡:
    - ä»»ä½• failed ç‹€æ…‹ â†’ decision: "block"
    - åªæœ‰ warning ç‹€æ…‹ â†’ decision: "allow" + è­¦å‘Šè¨Šæ¯
    - å…¨éƒ¨ passed â†’ decision: "allow"
    - éŒ¯èª¤ â†’ decision: "allow"ï¼ˆéé˜»å¡åŸå‰‡ï¼‰

    Args:
        check_results: æª¢æ¸¬çµæœ

    Returns:
        (decision, reason)
    """
    summary = check_results["summary"]
    overall_status = check_results["overall_status"]

    if overall_status == "error":
        return "allow", "âš ï¸ æª¢æ¸¬ç³»çµ±éŒ¯èª¤ï¼Œå…è¨±æ“ä½œç¹¼çºŒï¼ˆè«‹æŸ¥çœ‹æ—¥èªŒï¼‰"

    if overall_status == "partial":
        return "allow", f"âš ï¸ éƒ¨åˆ†æª¢æ¸¬å¤±æ•—ï¼ˆ{summary['errors']} å€‹éŒ¯èª¤ï¼‰ï¼Œå…è¨±æ“ä½œç¹¼çºŒ"

    if summary["failed"] > 0:
        failed_checks = [
            name for name, check in check_results["checks"].items()
            if check["status"] == "failed"
        ]
        reason = f"æª¢æ¸¬åˆ° {summary['failed']} å€‹ Code Smell éœ€è¦ä¿®æ­£: {', '.join(failed_checks)}"
        return "block", reason

    if summary["warnings"] > 0:
        warning_checks = [
            name for name, check in check_results["checks"].items()
            if check["status"] == "warning"
        ]
        reason = f"æª¢æ¸¬é€šéï¼Œä½†æœ‰ {summary['warnings']} å€‹è­¦å‘Šéœ€è¦æ³¨æ„: {', '.join(warning_checks)}"
        return "allow", reason

    reason = f"âœ… æ‰€æœ‰æª¢æ¸¬é€šéï¼ˆ{summary['total_checks']} é …æª¢æ¸¬ï¼‰"
    return "allow", reason


def save_check_report(check_results: Dict[str, Any], file_path: str) -> None:
    """
    å„²å­˜æª¢æ¸¬å ±å‘Š

    Args:
        check_results: æª¢æ¸¬çµæœ
        file_path: Ticket æª”æ¡ˆè·¯å¾‘
    """
    import os

    # å»ºç«‹å ±å‘Šç›®éŒ„
    project_dir = Path(os.getenv("CLAUDE_PROJECT_DIR", Path.cwd()))
    report_dir = project_dir / ".claude" / "hook-logs" / "ticket-quality-gate" / datetime.now().strftime("%Y-%m-%d")
    report_dir.mkdir(parents=True, exist_ok=True)

    # ç”¢ç”Ÿå ±å‘Šæª”å
    ticket_name = Path(file_path).stem
    timestamp = datetime.now().strftime("%H%M%S")

    # å„²å­˜ Markdown å ±å‘Š
    markdown_file = report_dir / f"check-{ticket_name}-{timestamp}.md"
    markdown_content = generate_markdown_report(check_results, file_path)
    markdown_file.write_text(markdown_content, encoding="utf-8")
    logging.info(f"Markdown å ±å‘Šå·²å„²å­˜: {markdown_file}")

    # å„²å­˜ JSON å ±å‘Š
    json_file = report_dir / f"check-{ticket_name}-{timestamp}.json"
    json_content = generate_json_report(check_results, file_path)
    json_file.write_text(json_content, encoding="utf-8")
    logging.info(f"JSON å ±å‘Šå·²å„²å­˜: {json_file}")


def print_error_json(error: Exception) -> None:
    """
    è¼¸å‡ºéŒ¯èª¤ JSON

    Args:
        error: ç•°å¸¸ç‰©ä»¶
    """
    error_output = {
        "decision": "allow",
        "reason": "Hook åŸ·è¡ŒéŒ¯èª¤ï¼Œå…è¨±æ“ä½œç¹¼çºŒï¼ˆè¨˜éŒ„éŒ¯èª¤æ—¥èªŒï¼‰",
        "hookSpecificOutput": {
            "hookEventName": "PostToolUse",
            "additionalContext": "âš ï¸ Ticket å“è³ªæª¢æ¸¬åŸ·è¡Œå¤±æ•—ï¼Œè«‹æŸ¥çœ‹æ—¥èªŒ: .claude/hook-logs/ticket-quality-gate/ticket-quality-gate.log"
        },
        "error": {
            "type": type(error).__name__,
            "message": str(error),
            "timestamp": datetime.now().isoformat()
        }
    }
    print(json.dumps(error_output, ensure_ascii=False, indent=2))


def main() -> int:
    """
    ä¸»å…¥å£é»

    åŸ·è¡Œæµç¨‹:
    1. è®€å– JSON è¼¸å…¥
    2. æª¢æŸ¥è§¸ç™¼æ¢ä»¶
    3. å¿«å–æª¢æŸ¥ï¼ˆè¨˜éŒ„æ™‚é–“ï¼‰
    4. åŸ·è¡Œæª¢æ¸¬ï¼ˆè¨˜éŒ„æ™‚é–“ï¼‰
    5. ç”¢ç”Ÿ Hook è¼¸å‡º
    6. å„²å­˜å ±å‘Š
    7. æ›´æ–°å¿«å–
    8. æ›´æ–°å¿«å–çµ±è¨ˆ
    9. æ±ºå®š exit code

    Returns:
        int - Exit code
    """
    import time

    try:
        # æ­¥é©Ÿ 1: åˆå§‹åŒ–æ—¥èªŒ
        setup_logging()
        logging.info("Ticket Quality Gate Hook å•Ÿå‹•")

        # æ­¥é©Ÿ 2: è®€å– JSON è¼¸å…¥
        input_data = read_json_from_stdin()

        # æ­¥é©Ÿ 3: é©—è­‰è¼¸å…¥æ ¼å¼
        if not validate_input(input_data):
            logging.error("è¼¸å…¥æ ¼å¼éŒ¯èª¤")
            print(json.dumps({
                "decision": "allow",
                "reason": "Hook è¼¸å…¥æ ¼å¼éŒ¯èª¤ï¼Œå…è¨±æ“ä½œç¹¼çºŒ"
            }, ensure_ascii=False, indent=2))
            return EXIT_SUCCESS

        # æ­¥é©Ÿ 4: æª¢æŸ¥è§¸ç™¼æ¢ä»¶
        if not should_trigger_check(input_data):
            logging.info("ä¸ç¬¦åˆè§¸ç™¼æ¢ä»¶ï¼Œè·³éæª¢æ¸¬")
            return EXIT_SUCCESS

        # æ­¥é©Ÿ 5: å¿«å–æª¢æŸ¥ï¼ˆè¨˜éŒ„é–‹å§‹æ™‚é–“ï¼‰
        file_path = input_data["tool_input"]["file_path"]
        ticket_content = input_data["tool_input"]["content"]
        file_hash = calculate_file_hash(ticket_content)

        start_time = time.time()
        cache_hit = should_skip_check_due_to_cache(file_path, file_hash)

        if cache_hit:
            # å¿«å–å‘½ä¸­ï¼šè¨˜éŒ„å¿«é€ŸåŸ·è¡Œæ™‚é–“
            execution_time = time.time() - start_time
            update_cache_stats(cache_hit=True, execution_time=execution_time)
            logging.info(f"å¿«å–å‘½ä¸­ï¼Œè·³éæª¢æ¸¬ï¼ŒåŸ·è¡Œæ™‚é–“: {execution_time:.3f}s")
            return EXIT_SUCCESS

        # æ­¥é©Ÿ 6: åŸ·è¡Œæª¢æ¸¬ï¼ˆå¿«å–æœªå‘½ä¸­ï¼‰
        check_results = run_all_checks(ticket_content, file_path)
        execution_time = time.time() - start_time

        # æ­¥é©Ÿ 7: ç”¢ç”Ÿ Hook è¼¸å‡º
        hook_output = generate_hook_output(check_results)
        print(json.dumps(hook_output, ensure_ascii=False, indent=2))

        # æ­¥é©Ÿ 8: å„²å­˜å ±å‘Š
        save_check_report(check_results, file_path)

        # æ­¥é©Ÿ 9: æ›´æ–°å¿«å–
        update_check_cache(file_path, file_hash, check_results)

        # æ­¥é©Ÿ 10: æ›´æ–°å¿«å–çµ±è¨ˆï¼ˆå¿«å–æœªå‘½ä¸­ï¼‰
        update_cache_stats(cache_hit=False, execution_time=execution_time)

        # æ­¥é©Ÿ 11: æ¸…ç†éæœŸå¿«å–
        cleanup_expired_cache()

        # æ­¥é©Ÿ 12: æ±ºå®š exit code
        if check_results["overall_status"] == "failed":
            logging.info(f"æª¢æ¸¬å¤±æ•—ï¼Œexit code = 2ï¼ˆé€šçŸ¥ Claudeï¼‰ï¼ŒåŸ·è¡Œæ™‚é–“: {execution_time:.3f}s")
            return EXIT_BLOCK  # 2
        else:
            logging.info(f"æª¢æ¸¬é€šéï¼Œexit code = 0ï¼ŒåŸ·è¡Œæ™‚é–“: {execution_time:.3f}s")
            return EXIT_SUCCESS  # 0

    except Exception as e:
        logging.critical(f"Hook åŸ·è¡ŒéŒ¯èª¤: {e}", exc_info=True)
        print_error_json(e)
        return EXIT_ERROR  # 1


if __name__ == "__main__":
    sys.exit(main())
